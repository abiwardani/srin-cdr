{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705eb3fb",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ffb47",
   "metadata": {},
   "source": [
    "## Load Interactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb53fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/amazon-custom-books/amazon-custom-books.inter\", \"r\", encoding=\"utf-8\") as f:\n",
    "    source_dataset = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]\n",
    "\n",
    "with open(\"dataset/amazon-custom-movies-tv/amazon-custom-movies-tv.inter\", \"r\", encoding=\"utf-8\") as f:\n",
    "    target_dataset = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659b7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_users = list(set([row[0] for row in source_dataset]))\n",
    "source_items = list(set([row[1] for row in source_dataset]))\n",
    "\n",
    "target_users = list(set([row[0] for row in target_dataset]))\n",
    "target_items = list(set([row[1] for row in target_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dad3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = list(set(source_users + target_users))\n",
    "all_items = list(set(source_items + target_items))\n",
    "\n",
    "n_users = len(all_users)\n",
    "n_source_items = len(source_items)\n",
    "n_target_items = len(target_items)\n",
    "n_items = len(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87501fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_interactions: 104080\n",
      "target_interactions: 120985\n",
      "\n",
      "n_users: 3859\n",
      "n_source_users: 2329\n",
      "n_target_users: 2346\n",
      "\n",
      "n_source_items: 4883\n",
      "n_target_items: 4929\n",
      "n_items: 9812\n",
      "\n",
      "overlap_users: 816\n",
      "overlap_items: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"source_interactions:\", len(source_dataset))\n",
    "print(\"target_interactions:\", len(target_dataset))\n",
    "print()\n",
    "print(\"n_users:\", n_users)\n",
    "print(\"n_source_users:\", len(source_users))\n",
    "print(\"n_target_users:\", len(target_users))\n",
    "print()\n",
    "print(\"n_source_items:\", n_source_items)\n",
    "print(\"n_target_items:\", n_target_items)\n",
    "print(\"n_items:\", n_items)\n",
    "print()\n",
    "print(\"overlap_users:\", len(source_users)+len(target_users)-n_users)\n",
    "print(\"overlap_items:\", n_source_items+n_target_items-n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55173a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {user: idx for idx, user in enumerate(all_users)}\n",
    "source_item_dict = {item: idx for idx, item in enumerate(source_items)}\n",
    "target_item_dict = {item: idx for idx, item in enumerate(target_items)}\n",
    "item_dict = {item: idx for idx, item in enumerate(all_items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b8cbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# raw dataset to torch dataset with integrated user ids but separate item ids\n",
    "\n",
    "tensor_source_users = torch.Tensor(np.array([user_dict[row[0]] for row in source_dataset]))\n",
    "tensor_source_items = torch.Tensor(np.array([source_item_dict[row[1]] for row in source_dataset]))\n",
    "tensor_source_ratings = torch.Tensor(np.array([float(row[2]) for row in source_dataset]))\n",
    "\n",
    "tensor_target_users = torch.Tensor(np.array([user_dict[row[0]] for row in target_dataset]))\n",
    "tensor_target_items = torch.Tensor(np.array([target_item_dict[row[1]] for row in target_dataset]))\n",
    "tensor_target_ratings = torch.Tensor(np.array([float(row[2]) for row in target_dataset]))\n",
    "\n",
    "source_dataset_torch = TensorDataset(tensor_source_users, tensor_source_items, tensor_source_ratings)\n",
    "target_dataset_torch = TensorDataset(tensor_target_users, tensor_target_items, tensor_target_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e99638",
   "metadata": {},
   "source": [
    "## Load Item Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab72768",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/amazon-custom-books/amazon-custom-books.embed\", \"r\", encoding=\"utf-8\") as f:\n",
    "    source_item_embed_file = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]\n",
    "\n",
    "with open(\"dataset/amazon-custom-movies-tv/amazon-custom-movies-tv.embed\", \"r\", encoding=\"utf-8\") as f:\n",
    "    target_item_embed_file = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7de7574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_item_embed_dict = {line[0]: list(map(float, line[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\"))) for line in source_item_embed_file}\n",
    "target_item_embed_dict = {line[0]: list(map(float, line[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\"))) for line in target_item_embed_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a57ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_source_item_dict = {source_item_dict[item]: item for item in source_items}\n",
    "reverse_target_item_dict = {target_item_dict[item]: item for item in target_items}\n",
    "\n",
    "source_item_feature_vectors = np.array([source_item_embed_dict[reverse_source_item_dict[idx]] for idx in range(n_source_items)])\n",
    "target_item_feature_vectors = np.array([target_item_embed_dict[reverse_target_item_dict[idx]] for idx in range(n_target_items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e712474",
   "metadata": {},
   "source": [
    "# Model Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fb6ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CMF(nn.Module):\n",
    "    \"\"\"\n",
    "    Collective Matrix Factorization for two domains sharing user embeddings.\n",
    "\n",
    "    Assumes datasets yield (user_idx, item_idx, rating) with 0-based integer indices.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items_source: int,\n",
    "        n_items_target: int,\n",
    "        emb_dim: int = 64,\n",
    "        use_bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, emb_dim)\n",
    "        self.item_emb_source = nn.Embedding(n_items_source, emb_dim)\n",
    "        self.item_emb_target = nn.Embedding(n_items_target, emb_dim)\n",
    "\n",
    "        self.use_bias = use_bias\n",
    "        if use_bias:\n",
    "            self.user_bias = nn.Embedding(n_users, 1)\n",
    "            self.item_bias_source = nn.Embedding(n_items_source, 1)\n",
    "            self.item_bias_target = nn.Embedding(n_items_target, 1)\n",
    "            self.global_bias = nn.Parameter(torch.zeros(1))\n",
    "        else:\n",
    "            # placeholders to simplify forward\n",
    "            self.register_buffer(\"user_bias\", torch.zeros(n_users, 1))\n",
    "            self.register_buffer(\"item_bias_source\", torch.zeros(n_items_source, 1))\n",
    "            self.register_buffer(\"item_bias_target\", torch.zeros(n_items_target, 1))\n",
    "            self.register_buffer(\"global_bias\", torch.zeros(1))\n",
    "\n",
    "        # init\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        nn.init.normal_(self.item_emb_source.weight, 0, 0.1)\n",
    "        nn.init.normal_(self.item_emb_target.weight, 0, 0.1)\n",
    "        if self.use_bias:\n",
    "            nn.init.zeros_(self.user_bias.weight)\n",
    "            nn.init.zeros_(self.item_bias_source.weight)\n",
    "            nn.init.zeros_(self.item_bias_target.weight)\n",
    "            nn.init.zeros_(self.global_bias)\n",
    "\n",
    "    def predict(self, users: torch.LongTensor, items: torch.LongTensor, domain: Literal[\"source\", \"target\"]):\n",
    "        \"\"\"\n",
    "        Predict ratings for a batch given domain.\n",
    "        domain: \"source\" or \"target\"\n",
    "        \"\"\"\n",
    "        u_emb = self.user_emb(users)\n",
    "        if domain == \"source\":\n",
    "            i_emb = self.item_emb_source(items)\n",
    "            if self.use_bias:\n",
    "                ub = self.user_bias(users).squeeze(-1)\n",
    "                ib = self.item_bias_source(items).squeeze(-1)\n",
    "            else:\n",
    "                ub = 0.0\n",
    "                ib = 0.0\n",
    "        elif domain == \"target\":\n",
    "            i_emb = self.item_emb_target(items)\n",
    "            if self.use_bias:\n",
    "                ub = self.user_bias(users).squeeze(-1)\n",
    "                ib = self.item_bias_target(items).squeeze(-1)\n",
    "            else:\n",
    "                ub = 0.0\n",
    "                ib = 0.0\n",
    "        else:\n",
    "            raise ValueError(\"domain must be 'source' or 'target'\")\n",
    "\n",
    "        dot = (u_emb * i_emb).sum(dim=-1)\n",
    "        return dot + (ub + ib + self.global_bias).squeeze()  # shape (batch,)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor, domain: Literal[\"source\", \"target\"]):\n",
    "        return self.predict(users, items, domain)\n",
    "\n",
    "\n",
    "def train_cmf(\n",
    "    model: CMF,\n",
    "    source_loader: DataLoader,\n",
    "    target_loader: DataLoader,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 0.0,\n",
    "    device: torch.device = None,\n",
    "    report_every: int = 1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Jointly train on source and target loaders. Each loader yields (user, item, rating).\n",
    "    \"\"\"\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        # Train on source domain\n",
    "        for users, items, ratings in source_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"source\")\n",
    "            loss = criterion(preds, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        # Train on target domain\n",
    "        for users, items, ratings in target_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"target\")\n",
    "            loss = criterion(preds, ratings)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        if ep % report_every == 0:\n",
    "            avg_loss = total_loss / max(1, n_batches)\n",
    "            print(f\"Epoch {ep}/{epochs} — avg MSE: {avg_loss:.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_cmf(model: CMF, loader: DataLoader, domain: Literal[\"source\", \"target\"], device: torch.device = None):\n",
    "    \"\"\"\n",
    "    Return RMSE on provided loader (domain indicates which item embeddings to use).\n",
    "    \"\"\"\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    se = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            preds = model(users, items, domain=domain)\n",
    "            se += ((preds - ratings) ** 2).sum().item()\n",
    "            n += ratings.numel()\n",
    "    rmse = math.sqrt(se / n) if n > 0 else float(\"nan\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2042f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c38fc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_loader = DataLoader(source_dataset_torch, batch_size=1024, shuffle=True)\n",
    "target_loader = DataLoader(target_dataset_torch, batch_size=1024, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894078d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 — avg MSE: 18.636065\n",
      "Epoch 2/50 — avg MSE: 18.415414\n",
      "Epoch 3/50 — avg MSE: 18.032449\n",
      "Epoch 4/50 — avg MSE: 17.013471\n",
      "Epoch 5/50 — avg MSE: 14.360445\n",
      "Epoch 6/50 — avg MSE: 9.993300\n",
      "Epoch 7/50 — avg MSE: 5.951675\n",
      "Epoch 8/50 — avg MSE: 3.436597\n",
      "Epoch 9/50 — avg MSE: 2.110143\n",
      "Epoch 10/50 — avg MSE: 1.428026\n",
      "Epoch 11/50 — avg MSE: 1.059915\n",
      "Epoch 12/50 — avg MSE: 0.852664\n",
      "Epoch 13/50 — avg MSE: 0.728021\n",
      "Epoch 14/50 — avg MSE: 0.647738\n",
      "Epoch 15/50 — avg MSE: 0.589273\n",
      "Epoch 16/50 — avg MSE: 0.544644\n",
      "Epoch 17/50 — avg MSE: 0.507299\n",
      "Epoch 18/50 — avg MSE: 0.473792\n",
      "Epoch 19/50 — avg MSE: 0.442900\n",
      "Epoch 20/50 — avg MSE: 0.413502\n",
      "Epoch 21/50 — avg MSE: 0.385857\n",
      "Epoch 22/50 — avg MSE: 0.358780\n",
      "Epoch 23/50 — avg MSE: 0.332561\n",
      "Epoch 24/50 — avg MSE: 0.307609\n",
      "Epoch 25/50 — avg MSE: 0.283845\n",
      "Epoch 26/50 — avg MSE: 0.260883\n",
      "Epoch 27/50 — avg MSE: 0.239688\n",
      "Epoch 28/50 — avg MSE: 0.219412\n",
      "Epoch 29/50 — avg MSE: 0.200611\n",
      "Epoch 30/50 — avg MSE: 0.183223\n",
      "Epoch 31/50 — avg MSE: 0.167148\n",
      "Epoch 32/50 — avg MSE: 0.152410\n",
      "Epoch 33/50 — avg MSE: 0.138530\n",
      "Epoch 34/50 — avg MSE: 0.126381\n",
      "Epoch 35/50 — avg MSE: 0.114988\n",
      "Epoch 36/50 — avg MSE: 0.104678\n",
      "Epoch 37/50 — avg MSE: 0.095446\n",
      "Epoch 38/50 — avg MSE: 0.086977\n",
      "Epoch 39/50 — avg MSE: 0.079152\n",
      "Epoch 40/50 — avg MSE: 0.072067\n",
      "Epoch 41/50 — avg MSE: 0.065682\n",
      "Epoch 42/50 — avg MSE: 0.059953\n",
      "Epoch 43/50 — avg MSE: 0.054527\n",
      "Epoch 44/50 — avg MSE: 0.049896\n",
      "Epoch 45/50 — avg MSE: 0.045389\n",
      "Epoch 46/50 — avg MSE: 0.041294\n",
      "Epoch 47/50 — avg MSE: 0.037672\n",
      "Epoch 48/50 — avg MSE: 0.034398\n",
      "Epoch 49/50 — avg MSE: 0.031395\n",
      "Epoch 50/50 — avg MSE: 0.028624\n",
      "Target RMSE: 0.15756752017527348\n"
     ]
    }
   ],
   "source": [
    "model = CMF(n_users, n_source_items, n_target_items, emb_dim=64, use_bias=False)\n",
    "\n",
    "train_cmf(model, source_loader, target_loader, epochs=50, lr=1e-3)\n",
    "\n",
    "rmse_target = evaluate_cmf(model, target_loader, domain=\"target\")\n",
    "\n",
    "print(\"Target RMSE:\", rmse_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8e8324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(tensor_target_users.long(), tensor_target_items.long(), 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc40fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_preds = [int(e >= 3) for e in preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "682c1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_ratings = [int(e >= 3) for e in tensor_target_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "698ccbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(bin_ratings, bin_preds)\n",
    "conf = precision_recall_fscore_support(bin_ratings, bin_preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74694575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9510435177914618\n",
      "prec: 0.9997985708119514\n",
      "recall: 0.9464117091595845\n",
      "f1: 0.9723729074448088\n"
     ]
    }
   ],
   "source": [
    "print(\"acc:\", acc)\n",
    "print(\"prec:\", conf[0])\n",
    "print(\"recall:\", conf[1])\n",
    "print(\"f1:\", conf[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136e1b6",
   "metadata": {},
   "source": [
    "# NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eaacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "# Neural collaborative filtering (NCF) for cross-domain recommendation\n",
    "# Uses precomputed item feature vectors for source / target domains.\n",
    "# Expects these variables to exist in the notebook:\n",
    "#   - user_dict (dict): maps user_id -> user_idx (0-based)\n",
    "#   - n_users (int)\n",
    "#   - source_item_feature_vectors (np.array or torch.Tensor)  # shape (n_source_items, feat_dim)\n",
    "#   - target_item_feature_vectors (np.array or torch.Tensor)  # shape (n_target_items, feat_dim)\n",
    "#   - source_loader, target_loader (torch.utils.data.DataLoader) or source_dataset_torch/target_dataset_torch\n",
    "# If prebuilt loaders are not available, you can create them from source_dataset_torch / target_dataset_torch.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Collaborative Filtering that concatenates a learned user embedding with provided\n",
    "    item feature vectors (from source/target) and passes them through an MLP to predict rating.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        source_item_features,  # numpy array or torch.Tensor (n_source_items, feat_dim)\n",
    "        target_item_features,  # numpy array or torch.Tensor (n_target_items, feat_dim)\n",
    "        user_emb_dim: int = 64,\n",
    "        mlp_layers: list = (128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        freeze_item_features: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # user embedding\n",
    "        self.user_emb = nn.Embedding(n_users, user_emb_dim)\n",
    "\n",
    "        # item features: convert to tensors and make Embedding-like lookup via from_pretrained\n",
    "        src_feat = torch.as_tensor(source_item_features, dtype=torch.float32)\n",
    "        tgt_feat = torch.as_tensor(target_item_features, dtype=torch.float32)\n",
    "        self.src_feat_dim = src_feat.shape[1]\n",
    "        self.tgt_feat_dim = tgt_feat.shape[1]\n",
    "\n",
    "        self.item_feat_src = nn.Embedding.from_pretrained(src_feat, freeze=freeze_item_features)\n",
    "        self.item_feat_tgt = nn.Embedding.from_pretrained(tgt_feat, freeze=freeze_item_features)\n",
    "\n",
    "        # MLP that takes concat(user_emb, item_feat) -> rating scalar\n",
    "        input_dim_src = user_emb_dim + self.src_feat_dim\n",
    "        input_dim_tgt = user_emb_dim + self.tgt_feat_dim\n",
    "        # For simplicity use same MLP architecture but different first layer shapes handled at forward\n",
    "\n",
    "        # Build MLP for source domain and target domain separately if feature dims differ\n",
    "        def build_mlp(input_dim):\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "\n",
    "            for hidden_dim in mlp_layers:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                prev_dim = hidden_dim\n",
    "\n",
    "            layers.append(nn.Linear(prev_dim, 1))  # final scalar\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.mlp_src = build_mlp(input_dim_src)\n",
    "        # reuse architecture for target but with target input dim\n",
    "        self.mlp_tgt = build_mlp(input_dim_tgt)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "\n",
    "        # pretrained item features already set; MLP init\n",
    "        for m in self.mlp_src:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "        for m in self.mlp_tgt:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor, domain: str):\n",
    "        \"\"\"\n",
    "        users: (batch,)\n",
    "        items: (batch,) -- item indices local to domain (0..n_items_domain-1)\n",
    "        domain: \"source\" or \"target\"\n",
    "        returns: (batch,) predicted scalar ratings\n",
    "        \"\"\"\n",
    "        u = self.user_emb(users)  # (batch, user_emb_dim)\n",
    "\n",
    "        if domain == \"source\":\n",
    "            i_feat = self.item_feat_src(items)  # (batch, feat_dim)\n",
    "            x = torch.cat([u, i_feat], dim=-1)\n",
    "            out = self.mlp_src(x).squeeze(-1)\n",
    "\n",
    "        elif domain == \"target\":\n",
    "            i_feat = self.item_feat_tgt(items)\n",
    "            x = torch.cat([u, i_feat], dim=-1)\n",
    "            out = self.mlp_tgt(x).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"domain must be 'source' or 'target'\")\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Training / evaluation helpers\n",
    "def train_ncf(\n",
    "    model: nn.Module,\n",
    "    source_loader,\n",
    "    target_loader,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 0.0,\n",
    "    device: torch.device = None,\n",
    "    report_every: int = 1,\n",
    "):\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for users, items, ratings in source_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"source\")\n",
    "            loss = loss_fn(preds, ratings)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        for users, items, ratings in target_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"target\")\n",
    "            loss = loss_fn(preds, ratings)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        if ep % report_every == 0:\n",
    "            print(f\"Epoch {ep}/{epochs} avg MSE: {total_loss / max(1, n_batches):.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_ncf(model: nn.Module, loader, domain: str, device: torch.device = None):\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    se = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            preds = model(users, items, domain=domain)\n",
    "            se += ((preds - ratings) ** 2).sum().item()\n",
    "            n += ratings.numel()\n",
    "    rmse = math.sqrt(se / n) if n > 0 else float(\"nan\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c66744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "class NCF(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Collaborative Filtering that concatenates a learned user embedding with provided\n",
    "    item feature vectors (from source/target) and passes them through an MLP to predict rating.\n",
    "\n",
    "    This version shares a base user embedding across domains and applies small domain-specific\n",
    "    adapters (learned transforms) so the model can learn domain-specific user behavior while\n",
    "    still sharing signal across domains (helpful for overlapping users).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        source_item_features,  # numpy array or torch.Tensor (n_source_items, feat_dim)\n",
    "        target_item_features,  # numpy array or torch.Tensor (n_target_items, feat_dim)\n",
    "        user_emb_dim: int = 64,\n",
    "        mlp_layers: list = (128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        freeze_item_features: bool = True,\n",
    "        adapter_hidden: int = None,  # if set, use a small hidden layer in adapters\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # shared base user embedding (size = total unique users across both domains)\n",
    "        self.user_emb = nn.Embedding(n_users, user_emb_dim)\n",
    "\n",
    "        # lightweight domain adapters: map base user embedding -> domain-specific user embedding\n",
    "        if adapter_hidden is None:\n",
    "            # single linear adapter\n",
    "            self.user_adapter_src = nn.Linear(user_emb_dim, user_emb_dim)\n",
    "            self.user_adapter_tgt = nn.Linear(user_emb_dim, user_emb_dim)\n",
    "        else:\n",
    "            self.user_adapter_src = nn.Sequential(\n",
    "                nn.Linear(user_emb_dim, adapter_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(adapter_hidden, user_emb_dim),\n",
    "            )\n",
    "            self.user_adapter_tgt = nn.Sequential(\n",
    "                nn.Linear(user_emb_dim, adapter_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(adapter_hidden, user_emb_dim),\n",
    "            )\n",
    "\n",
    "        # item features: convert to tensors and make Embedding-like lookup via from_pretrained\n",
    "        src_feat = torch.as_tensor(source_item_features, dtype=torch.float32)\n",
    "        tgt_feat = torch.as_tensor(target_item_features, dtype=torch.float32)\n",
    "        self.src_feat_dim = src_feat.shape[1]\n",
    "        self.tgt_feat_dim = tgt_feat.shape[1]\n",
    "\n",
    "        self.item_feat_src = nn.Embedding.from_pretrained(src_feat, freeze=freeze_item_features)\n",
    "        self.item_feat_tgt = nn.Embedding.from_pretrained(tgt_feat, freeze=freeze_item_features)\n",
    "\n",
    "        # MLPs for each domain\n",
    "        input_dim_src = user_emb_dim + self.src_feat_dim\n",
    "        input_dim_tgt = user_emb_dim + self.tgt_feat_dim\n",
    "\n",
    "        def build_mlp(input_dim):\n",
    "            layers = []\n",
    "            prev = input_dim\n",
    "            for h in mlp_layers:\n",
    "                layers.append(nn.Linear(prev, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                prev = h\n",
    "            layers.append(nn.Linear(prev, 1))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.mlp_src = build_mlp(input_dim_src)\n",
    "        self.mlp_tgt = build_mlp(input_dim_tgt)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        # adapter init\n",
    "        def init_adapter(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        self.user_adapter_src.apply(init_adapter)\n",
    "        self.user_adapter_tgt.apply(init_adapter)\n",
    "        # MLP init\n",
    "        for m in self.mlp_src:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in self.mlp_tgt:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor, domain: str):\n",
    "        \"\"\"\n",
    "        users: (batch,)\n",
    "        items: (batch,) -- item indices local to domain (0..n_items_domain-1)\n",
    "        domain: \"source\" or \"target\"\n",
    "        returns: (batch,) predicted scalar ratings\n",
    "        \"\"\"\n",
    "        u = self.user_emb(users)  # (batch, user_emb_dim)\n",
    "        # domain-specific adapter: lets the model learn per-domain user behavior while sharing base info\n",
    "        if domain == \"source\":\n",
    "            u_dom = self.user_adapter_src(u)\n",
    "            i_feat = self.item_feat_src(items)\n",
    "            x = torch.cat([u_dom, i_feat], dim=-1)\n",
    "            out = self.mlp_src(x).squeeze(-1)\n",
    "        elif domain == \"target\":\n",
    "            u_dom = self.user_adapter_tgt(u)\n",
    "            i_feat = self.item_feat_tgt(items)\n",
    "            x = torch.cat([u_dom, i_feat], dim=-1)\n",
    "            out = self.mlp_tgt(x).squeeze(-1)\n",
    "        else:\n",
    "            raise ValueError(\"domain must be 'source' or 'target'\")\n",
    "        return out\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181772f9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Example usage (assumes the named variables exist in the notebook):\n",
    "# - source_item_feature_vectors, target_item_feature_vectors: arrays/tensors of item features\n",
    "# - source_loader, target_loader: DataLoader objects producing (user_idx, item_idx, rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8613ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 avg MSE: 3.040604\n",
      "Epoch 2/50 avg MSE: 1.408292\n",
      "Epoch 3/50 avg MSE: 1.271468\n",
      "Epoch 4/50 avg MSE: 1.212633\n",
      "Epoch 5/50 avg MSE: 1.175297\n",
      "Epoch 6/50 avg MSE: 1.136314\n",
      "Epoch 7/50 avg MSE: 1.113781\n",
      "Epoch 8/50 avg MSE: 1.085496\n",
      "Epoch 9/50 avg MSE: 1.059976\n",
      "Epoch 10/50 avg MSE: 1.043349\n",
      "Epoch 11/50 avg MSE: 1.024997\n",
      "Epoch 12/50 avg MSE: 1.004933\n",
      "Epoch 13/50 avg MSE: 0.988168\n",
      "Epoch 14/50 avg MSE: 0.970328\n",
      "Epoch 15/50 avg MSE: 0.953801\n",
      "Epoch 16/50 avg MSE: 0.931623\n",
      "Epoch 17/50 avg MSE: 0.916105\n",
      "Epoch 18/50 avg MSE: 0.898908\n",
      "Epoch 19/50 avg MSE: 0.881925\n",
      "Epoch 20/50 avg MSE: 0.862051\n",
      "Epoch 21/50 avg MSE: 0.847788\n",
      "Epoch 22/50 avg MSE: 0.831449\n",
      "Epoch 23/50 avg MSE: 0.812696\n",
      "Epoch 24/50 avg MSE: 0.797843\n",
      "Epoch 25/50 avg MSE: 0.781795\n",
      "Epoch 26/50 avg MSE: 0.762961\n",
      "Epoch 27/50 avg MSE: 0.748274\n",
      "Epoch 28/50 avg MSE: 0.734222\n",
      "Epoch 29/50 avg MSE: 0.716033\n",
      "Epoch 30/50 avg MSE: 0.698651\n",
      "Epoch 31/50 avg MSE: 0.688903\n",
      "Epoch 32/50 avg MSE: 0.675081\n",
      "Epoch 33/50 avg MSE: 0.662427\n",
      "Epoch 34/50 avg MSE: 0.653715\n",
      "Epoch 35/50 avg MSE: 0.643205\n",
      "Epoch 36/50 avg MSE: 0.634367\n",
      "Epoch 37/50 avg MSE: 0.619963\n",
      "Epoch 38/50 avg MSE: 0.611793\n",
      "Epoch 39/50 avg MSE: 0.602002\n",
      "Epoch 40/50 avg MSE: 0.591835\n",
      "Epoch 41/50 avg MSE: 0.584090\n",
      "Epoch 42/50 avg MSE: 0.578574\n",
      "Epoch 43/50 avg MSE: 0.568345\n",
      "Epoch 44/50 avg MSE: 0.558311\n",
      "Epoch 45/50 avg MSE: 0.551414\n",
      "Epoch 46/50 avg MSE: 0.545100\n",
      "Epoch 47/50 avg MSE: 0.539167\n",
      "Epoch 48/50 avg MSE: 0.530731\n",
      "Epoch 49/50 avg MSE: 0.522152\n",
      "Epoch 50/50 avg MSE: 0.517012\n",
      "Target RMSE: 0.627872705477407\n"
     ]
    }
   ],
   "source": [
    "model = NCF(n_users=n_users,\n",
    "                 source_item_features=source_item_feature_vectors,\n",
    "                 target_item_features=target_item_feature_vectors,\n",
    "                 user_emb_dim=64,\n",
    "                 mlp_layers=(128,64,32),\n",
    "                 dropout=0.2,\n",
    "                 freeze_item_features=True)\n",
    "\n",
    "train_ncf(model, source_loader, target_loader, epochs=50, lr=1e-3)\n",
    "print(\"Target RMSE:\", evaluate_ncf(model, target_loader, domain=\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94c63c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.forward(tensor_target_users.long(), tensor_target_items.long(), 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b6b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_preds = [int(e >= 3) for e in preds]\n",
    "bin_ratings = [int(e >= 3) for e in tensor_target_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b674bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(bin_ratings, bin_preds)\n",
    "conf = precision_recall_fscore_support(bin_ratings, bin_preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b45e3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9506054469562343\n",
      "prec: 0.9757467799397095\n",
      "recall: 0.969846371758553\n",
      "f1: 0.9727876287533127\n"
     ]
    }
   ],
   "source": [
    "print(\"acc:\", acc)\n",
    "print(\"prec:\", conf[0])\n",
    "print(\"recall:\", conf[1])\n",
    "print(\"f1:\", conf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39263689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
