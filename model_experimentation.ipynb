{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "705eb3fb",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2ffb47",
   "metadata": {},
   "source": [
    "## Load Interactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfb53fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/amazon-custom-books/amazon-custom-books.inter\", \"r\", encoding=\"utf-8\") as f:\n",
    "    source_dataset = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]\n",
    "\n",
    "with open(\"dataset/amazon-custom-movies-tv/amazon-custom-movies-tv.inter\", \"r\", encoding=\"utf-8\") as f:\n",
    "    target_dataset = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "659b7505",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_users = list(set([row[0] for row in source_dataset]))\n",
    "source_items = list(set([row[1] for row in source_dataset]))\n",
    "\n",
    "target_users = list(set([row[0] for row in target_dataset]))\n",
    "target_items = list(set([row[1] for row in target_dataset]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0dad3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_users = list(set(source_users + target_users))\n",
    "all_items = list(set(source_items + target_items))\n",
    "\n",
    "n_users = len(all_users)\n",
    "n_source_items = len(source_items)\n",
    "n_target_items = len(target_items)\n",
    "n_items = len(all_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87501fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_interactions: 104080\n",
      "target_interactions: 120985\n",
      "\n",
      "n_users: 3859\n",
      "n_source_users: 2329\n",
      "n_target_users: 2346\n",
      "\n",
      "n_source_items: 4883\n",
      "n_target_items: 4929\n",
      "n_items: 9812\n",
      "\n",
      "overlap_users: 816\n",
      "overlap_items: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"source_interactions:\", len(source_dataset))\n",
    "print(\"target_interactions:\", len(target_dataset))\n",
    "print()\n",
    "print(\"n_users:\", n_users)\n",
    "print(\"n_source_users:\", len(source_users))\n",
    "print(\"n_target_users:\", len(target_users))\n",
    "print()\n",
    "print(\"n_source_items:\", n_source_items)\n",
    "print(\"n_target_items:\", n_target_items)\n",
    "print(\"n_items:\", n_items)\n",
    "print()\n",
    "print(\"overlap_users:\", len(source_users)+len(target_users)-n_users)\n",
    "print(\"overlap_items:\", n_source_items+n_target_items-n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55173a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dict = {user: idx for idx, user in enumerate(all_users)}\n",
    "source_item_dict = {item: idx for idx, item in enumerate(source_items)}\n",
    "target_item_dict = {item: idx for idx, item in enumerate(target_items)}\n",
    "item_dict = {item: idx for idx, item in enumerate(all_items)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b8cbb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset\n",
    "\n",
    "# raw dataset to torch dataset with integrated user ids but separate item ids\n",
    "\n",
    "tensor_source_users = torch.Tensor(np.array([user_dict[row[0]] for row in source_dataset]))\n",
    "tensor_source_items = torch.Tensor(np.array([source_item_dict[row[1]] for row in source_dataset]))\n",
    "tensor_source_ratings = torch.Tensor(np.array([float(row[2]) for row in source_dataset]))\n",
    "tensor_source_clicks = torch.Tensor(np.array([1.0 if float(row[2]) >= 3.0 else 0.0 for row in source_dataset]))\n",
    "\n",
    "tensor_target_users = torch.Tensor(np.array([user_dict[row[0]] for row in target_dataset]))\n",
    "tensor_target_items = torch.Tensor(np.array([target_item_dict[row[1]] for row in target_dataset]))\n",
    "tensor_target_ratings = torch.Tensor(np.array([float(row[2]) for row in target_dataset]))\n",
    "tensor_target_clicks = torch.Tensor(np.array([1.0 if float(row[2]) >= 3.0 else 0.0 for row in target_dataset]))\n",
    "\n",
    "source_dataset_torch = TensorDataset(tensor_source_users, tensor_source_items, tensor_source_ratings, tensor_source_clicks)\n",
    "target_dataset_torch = TensorDataset(tensor_target_users, tensor_target_items, tensor_target_ratings, tensor_target_clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e99638",
   "metadata": {},
   "source": [
    "## Load Item Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eab72768",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dataset/amazon-custom-books/amazon-custom-books.embed\", \"r\", encoding=\"utf-8\") as f:\n",
    "    source_item_embed_file = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]\n",
    "\n",
    "with open(\"dataset/amazon-custom-movies-tv/amazon-custom-movies-tv.embed\", \"r\", encoding=\"utf-8\") as f:\n",
    "    target_item_embed_file = [line.split(\"\\t\") for line in f.read().split(\"\\n\")][1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de7574b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_item_embed_dict = {line[0]: list(map(float, line[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\"))) for line in source_item_embed_file}\n",
    "target_item_embed_dict = {line[0]: list(map(float, line[1].replace(\"[\", \"\").replace(\"]\", \"\").split(\",\"))) for line in target_item_embed_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "32a57ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_source_item_dict = {source_item_dict[item]: item for item in source_items}\n",
    "reverse_target_item_dict = {target_item_dict[item]: item for item in target_items}\n",
    "\n",
    "source_item_feature_vectors = np.array([source_item_embed_dict[reverse_source_item_dict[idx]] for idx in range(n_source_items)])\n",
    "target_item_feature_vectors = np.array([target_item_embed_dict[reverse_target_item_dict[idx]] for idx in range(n_target_items)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e712474",
   "metadata": {},
   "source": [
    "# Model Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f97a53ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_train_dataset, source_test_dataset = torch.utils.data.random_split(source_dataset_torch, [0.8, 0.2])\n",
    "target_train_dataset, target_test_dataset = torch.utils.data.random_split(target_dataset_torch, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "add3bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Literal\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CMF(nn.Module):\n",
    "    \"\"\"\n",
    "    Collective Matrix Factorization for two domains sharing user embeddings.\n",
    "\n",
    "    Assumes datasets yield (user_idx, item_idx, rating) with 0-based integer indices.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        n_items: int,\n",
    "        embedding_dim: int = 64,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, embedding_dim)\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.loss = nn.BCELoss()\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def get_model_info(self):\n",
    "        return {\n",
    "            \"model_type\": \"CMF\",\n",
    "            \"n_users\": self.user_emb.num_embeddings,\n",
    "            \"n_items\": self.item_emb.num_embeddings,\n",
    "            \"embedding_dim\": self.user_emb.embedding_dim,\n",
    "        }\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        nn.init.normal_(self.item_emb.weight, 0, 0.1)\n",
    "\n",
    "    def predict(self, users: torch.LongTensor, items: torch.LongTensor):\n",
    "        \"\"\"\n",
    "        Predict ratings for a batch given domain.\n",
    "        domain: \"source\" or \"target\"\n",
    "        \"\"\"\n",
    "        user_embedding = self.user_emb(users)\n",
    "        item_embedding = self.item_emb(items)\n",
    "\n",
    "        return self.sigmoid(torch.mul(user_embedding, item_embedding).sum(dim=-1)) # shape (batch,)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor):\n",
    "        return self.predict(users, items)\n",
    "    \n",
    "    def calculate_loss(self, users: torch.LongTensor, items: torch.LongTensor, clicks: torch.FloatTensor):\n",
    "        preds = self.forward(users, items)\n",
    "        loss = self.loss(preds, clicks)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def __str__(self):\n",
    "        info = self.get_model_info()\n",
    "\n",
    "        return \"\\n\".join([f\"{key}: {value}\" for key, value in info.items()])\n",
    "\n",
    "class CMFTrainer():\n",
    "    def __init__(self, model: CMF):\n",
    "        self.model = model\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        source_loader: DataLoader,\n",
    "        target_loader: DataLoader,\n",
    "        epochs: int = 10,\n",
    "        lr: float = 1e-3,\n",
    "        alpha: float = 0.2,\n",
    "        weight_decay: float = 0.0,\n",
    "        report_every: int = 1,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Jointly train on source and target loaders. Each loader yields (user, item, rating).\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = lr\n",
    "        self.alpha = alpha\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate, weight_decay=self.weight_decay)\n",
    "\n",
    "        for ep in range(1, epochs + 1):\n",
    "            model.train()\n",
    "            total_loss = 0.0\n",
    "            n_batches = 0\n",
    "\n",
    "            # Train on source domain\n",
    "            for users, items, _, clicks in source_loader:\n",
    "                users = users.long()\n",
    "                items = items.long()\n",
    "                clicks = clicks.float()\n",
    "\n",
    "                loss = alpha*model.calculate_loss(users, items, clicks)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "            # Train on target domain\n",
    "            for users, items, _, clicks in target_loader:\n",
    "                users = users.long()\n",
    "                items = items.long()\n",
    "                clicks = clicks.float()\n",
    "\n",
    "                loss = alpha*model.calculate_loss(users, items, clicks)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "            if ep % report_every == 0:\n",
    "                avg_loss = total_loss / max(1, n_batches)\n",
    "                print(f\"Epoch {ep}/{epochs} — avg BCE: {avg_loss:.6f}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def evaluate(self, loader: DataLoader):\n",
    "        \"\"\"\n",
    "        Return BCE Loss on provided loader (domain indicates which item embeddings to use).\n",
    "        \"\"\"\n",
    "        model = self.model\n",
    "        model.eval()\n",
    "        total_loss = 0.0\n",
    "        n = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for users, items, _, clicks in loader:\n",
    "                users = users.long()\n",
    "                items = items.long()\n",
    "                clicks = clicks.float()\n",
    "\n",
    "                loss = model.calculate_loss(users, items, clicks)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                n += 1\n",
    "                \n",
    "        bce = math.sqrt(total_loss / n) if n > 0 else float(\"nan\")\n",
    "\n",
    "        return bce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2042f",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c38fc027",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_source_loader = DataLoader(source_train_dataset, batch_size=1024, shuffle=True)\n",
    "train_target_loader = DataLoader(target_train_dataset, batch_size=1024, shuffle=True)\n",
    "test_source_loader = DataLoader(source_test_dataset, batch_size=1024, shuffle=False)\n",
    "test_target_loader = DataLoader(target_test_dataset, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "894078d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 — avg BCE: 0.138805\n",
      "Epoch 2/20 — avg BCE: 0.136236\n",
      "Epoch 3/20 — avg BCE: 0.132551\n",
      "Epoch 4/20 — avg BCE: 0.124444\n",
      "Epoch 5/20 — avg BCE: 0.106470\n",
      "Epoch 6/20 — avg BCE: 0.081095\n",
      "Epoch 7/20 — avg BCE: 0.060146\n",
      "Epoch 8/20 — avg BCE: 0.047614\n",
      "Epoch 9/20 — avg BCE: 0.040434\n",
      "Epoch 10/20 — avg BCE: 0.035814\n",
      "Epoch 11/20 — avg BCE: 0.032432\n",
      "Epoch 12/20 — avg BCE: 0.029550\n",
      "Epoch 13/20 — avg BCE: 0.027017\n",
      "Epoch 14/20 — avg BCE: 0.024614\n",
      "Epoch 15/20 — avg BCE: 0.022374\n",
      "Epoch 16/20 — avg BCE: 0.020271\n",
      "Epoch 17/20 — avg BCE: 0.018237\n",
      "Epoch 18/20 — avg BCE: 0.016377\n",
      "Epoch 19/20 — avg BCE: 0.014663\n",
      "Epoch 20/20 — avg BCE: 0.013056\n",
      "Target BCE: 0.5059268536968287\n"
     ]
    }
   ],
   "source": [
    "model = CMF(n_users, n_items, embedding_dim=64)\n",
    "trainer = CMFTrainer(model)\n",
    "\n",
    "trainer.train(train_source_loader, train_target_loader, epochs=20, lr=1e-3)\n",
    "\n",
    "bce_target = trainer.evaluate(test_target_loader)\n",
    "\n",
    "print(\"Target BCE:\", bce_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9edd4d2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3739,\n",
       " 33833,\n",
       " 35424,\n",
       " 43961,\n",
       " 38331,\n",
       " 39876,\n",
       " 56404,\n",
       " 108335,\n",
       " 70641,\n",
       " 9886,\n",
       " 38054,\n",
       " 52026,\n",
       " 100040,\n",
       " 117421,\n",
       " 105592,\n",
       " 70162,\n",
       " 28662,\n",
       " 68282,\n",
       " 100284,\n",
       " 78594,\n",
       " 66415,\n",
       " 5053,\n",
       " 70411,\n",
       " 23948,\n",
       " 39828,\n",
       " 92263,\n",
       " 87407,\n",
       " 85420,\n",
       " 29234,\n",
       " 68698,\n",
       " 68995,\n",
       " 112332,\n",
       " 71036,\n",
       " 64851,\n",
       " 43850,\n",
       " 66222,\n",
       " 112216,\n",
       " 112201,\n",
       " 58488,\n",
       " 99886,\n",
       " 88342,\n",
       " 51986,\n",
       " 82038,\n",
       " 83237,\n",
       " 19607,\n",
       " 58196,\n",
       " 13183,\n",
       " 18412,\n",
       " 79565,\n",
       " 114420,\n",
       " 75706,\n",
       " 84180,\n",
       " 41095,\n",
       " 18733,\n",
       " 77720,\n",
       " 77035,\n",
       " 26411,\n",
       " 78117,\n",
       " 79316,\n",
       " 90120,\n",
       " 67266,\n",
       " 55674,\n",
       " 92500,\n",
       " 22481,\n",
       " 73267,\n",
       " 14135,\n",
       " 120564,\n",
       " 77974,\n",
       " 23213,\n",
       " 35375,\n",
       " 70520,\n",
       " 90106,\n",
       " 64379,\n",
       " 10922,\n",
       " 48122,\n",
       " 116227,\n",
       " 7824,\n",
       " 10212,\n",
       " 56330,\n",
       " 10033,\n",
       " 54075,\n",
       " 119198,\n",
       " 106888,\n",
       " 110316,\n",
       " 37215,\n",
       " 60870,\n",
       " 20879,\n",
       " 113311,\n",
       " 48579,\n",
       " 72333,\n",
       " 18888,\n",
       " 56972,\n",
       " 77175,\n",
       " 90415,\n",
       " 108135,\n",
       " 22322,\n",
       " 104678,\n",
       " 52040,\n",
       " 46370,\n",
       " 62215,\n",
       " 3849,\n",
       " 115640,\n",
       " 117309,\n",
       " 73150,\n",
       " 43496,\n",
       " 118006,\n",
       " 59111,\n",
       " 111243,\n",
       " 34455,\n",
       " 72995,\n",
       " 58131,\n",
       " 49661,\n",
       " 62515,\n",
       " 12615,\n",
       " 44251,\n",
       " 31478,\n",
       " 28233,\n",
       " 64262,\n",
       " 11654,\n",
       " 44304,\n",
       " 110723,\n",
       " 21626,\n",
       " 4664,\n",
       " 48918,\n",
       " 25923,\n",
       " 88293,\n",
       " 87427,\n",
       " 107620,\n",
       " 58320,\n",
       " 71910,\n",
       " 19979,\n",
       " 61713,\n",
       " 94438,\n",
       " 46202,\n",
       " 88988,\n",
       " 80350,\n",
       " 65611,\n",
       " 104626,\n",
       " 85933,\n",
       " 115479,\n",
       " 43809,\n",
       " 28902,\n",
       " 43085,\n",
       " 77099,\n",
       " 41478,\n",
       " 27558,\n",
       " 80688,\n",
       " 85427,\n",
       " 34274,\n",
       " 26330,\n",
       " 91973,\n",
       " 46170,\n",
       " 78892,\n",
       " 117763,\n",
       " 67146,\n",
       " 36650,\n",
       " 46644,\n",
       " 63864,\n",
       " 96066,\n",
       " 15305,\n",
       " 48470,\n",
       " 52015,\n",
       " 13404,\n",
       " 35442,\n",
       " 7951,\n",
       " 97487,\n",
       " 94061,\n",
       " 77385,\n",
       " 94180,\n",
       " 88181,\n",
       " 111665,\n",
       " 10504,\n",
       " 15358,\n",
       " 25319,\n",
       " 60442,\n",
       " 28772,\n",
       " 83494,\n",
       " 103067,\n",
       " 86645,\n",
       " 114173,\n",
       " 15294,\n",
       " 116073,\n",
       " 19193,\n",
       " 36296,\n",
       " 105778,\n",
       " 110082,\n",
       " 53735,\n",
       " 87212,\n",
       " 433,\n",
       " 52772,\n",
       " 43352,\n",
       " 95190,\n",
       " 5980,\n",
       " 26968,\n",
       " 20637,\n",
       " 22310,\n",
       " 84165,\n",
       " 77914,\n",
       " 37601,\n",
       " 86199,\n",
       " 97987,\n",
       " 53663,\n",
       " 75126,\n",
       " 90288,\n",
       " 55735,\n",
       " 90211,\n",
       " 79635,\n",
       " 92520,\n",
       " 85661,\n",
       " 35466,\n",
       " 56137,\n",
       " 31062,\n",
       " 20492,\n",
       " 35045,\n",
       " 75070,\n",
       " 58834,\n",
       " 96916,\n",
       " 99941,\n",
       " 33255,\n",
       " 22565,\n",
       " 92340,\n",
       " 33702,\n",
       " 48354,\n",
       " 99531,\n",
       " 118370,\n",
       " 52169,\n",
       " 4535,\n",
       " 51206,\n",
       " 5067,\n",
       " 65476,\n",
       " 33720,\n",
       " 80168,\n",
       " 30742,\n",
       " 110606,\n",
       " 63478,\n",
       " 12834,\n",
       " 68424,\n",
       " 107502,\n",
       " 1636,\n",
       " 11414,\n",
       " 81171,\n",
       " 29898,\n",
       " 34053,\n",
       " 25296,\n",
       " 101073,\n",
       " 110713,\n",
       " 32545,\n",
       " 51848,\n",
       " 16693,\n",
       " 74237,\n",
       " 80631,\n",
       " 74774,\n",
       " 118425,\n",
       " 2204,\n",
       " 96507,\n",
       " 108158,\n",
       " 36377,\n",
       " 11267,\n",
       " 47537,\n",
       " 68396,\n",
       " 53242,\n",
       " 103944,\n",
       " 91702,\n",
       " 79058,\n",
       " 6547,\n",
       " 49475,\n",
       " 74293,\n",
       " 61797,\n",
       " 5797,\n",
       " 27846,\n",
       " 33788,\n",
       " 7247,\n",
       " 40896,\n",
       " 28310,\n",
       " 61485,\n",
       " 41757,\n",
       " 62332,\n",
       " 86709,\n",
       " 59137,\n",
       " 48706,\n",
       " 116954,\n",
       " 28741,\n",
       " 78173,\n",
       " 36230,\n",
       " 102832,\n",
       " 92543,\n",
       " 4595,\n",
       " 53402,\n",
       " 96001,\n",
       " 56087,\n",
       " 52800,\n",
       " 52724,\n",
       " 82370,\n",
       " 63098,\n",
       " 73487,\n",
       " 21414,\n",
       " 16652,\n",
       " 57507,\n",
       " 9059,\n",
       " 76293,\n",
       " 70834,\n",
       " 30946,\n",
       " 102926,\n",
       " 60336,\n",
       " 3035,\n",
       " 90315,\n",
       " 68493,\n",
       " 62225,\n",
       " 58295,\n",
       " 25773,\n",
       " 84381,\n",
       " 70338,\n",
       " 27264,\n",
       " 10017,\n",
       " 8215,\n",
       " 9191,\n",
       " 6529,\n",
       " 48527,\n",
       " 113723,\n",
       " 110111,\n",
       " 41286,\n",
       " 6317,\n",
       " 70702,\n",
       " 48227,\n",
       " 54605,\n",
       " 19290,\n",
       " 42043,\n",
       " 86090,\n",
       " 51799,\n",
       " 91546,\n",
       " 7279,\n",
       " 89642,\n",
       " 16058,\n",
       " 113321,\n",
       " 45301,\n",
       " 90176,\n",
       " 4771,\n",
       " 120008,\n",
       " 2160,\n",
       " 95298,\n",
       " 27141,\n",
       " 103753,\n",
       " 98308,\n",
       " 112464,\n",
       " 20100,\n",
       " 75483,\n",
       " 20263,\n",
       " 31885,\n",
       " 114271,\n",
       " 53943,\n",
       " 43802,\n",
       " 21345,\n",
       " 72632,\n",
       " 25614,\n",
       " 46533,\n",
       " 97348,\n",
       " 35733,\n",
       " 117872,\n",
       " 59714,\n",
       " 45809,\n",
       " 119498,\n",
       " 18090,\n",
       " 81406,\n",
       " 28091,\n",
       " 22876,\n",
       " 86,\n",
       " 19251,\n",
       " 112191,\n",
       " 24340,\n",
       " 113800,\n",
       " 48501,\n",
       " 55245,\n",
       " 97644,\n",
       " 113300,\n",
       " 109589,\n",
       " 29907,\n",
       " 26524,\n",
       " 19324,\n",
       " 31711,\n",
       " 103244,\n",
       " 30967,\n",
       " 80144,\n",
       " 82048,\n",
       " 113549,\n",
       " 9706,\n",
       " 31414,\n",
       " 106089,\n",
       " 72717,\n",
       " 19146,\n",
       " 106440,\n",
       " 83303,\n",
       " 50165,\n",
       " 29433,\n",
       " 111367,\n",
       " 65996,\n",
       " 50525,\n",
       " 107633,\n",
       " 86797,\n",
       " 98444,\n",
       " 79891,\n",
       " 75384,\n",
       " 46489,\n",
       " 5362,\n",
       " 5515,\n",
       " 70680,\n",
       " 14656,\n",
       " 10388,\n",
       " 78890,\n",
       " 315,\n",
       " 60558,\n",
       " 18400,\n",
       " 111960,\n",
       " 78292,\n",
       " 18190,\n",
       " 60263,\n",
       " 19223,\n",
       " 40375,\n",
       " 55677,\n",
       " 113394,\n",
       " 18884,\n",
       " 24875,\n",
       " 99000,\n",
       " 26430,\n",
       " 45435,\n",
       " 12785,\n",
       " 34157,\n",
       " 74665,\n",
       " 38565,\n",
       " 5890,\n",
       " 26103,\n",
       " 108537,\n",
       " 78637,\n",
       " 101049,\n",
       " 120582,\n",
       " 53385,\n",
       " 16321,\n",
       " 104066,\n",
       " 98840,\n",
       " 25717,\n",
       " 108384,\n",
       " 36258,\n",
       " 108082,\n",
       " 25040,\n",
       " 103157,\n",
       " 34012,\n",
       " 40817,\n",
       " 63601,\n",
       " 28851,\n",
       " 94211,\n",
       " 72771,\n",
       " 51508,\n",
       " 45161,\n",
       " 25425,\n",
       " 79695,\n",
       " 44838,\n",
       " 12886,\n",
       " 33144,\n",
       " 1982,\n",
       " 101754,\n",
       " 3501,\n",
       " 62670,\n",
       " 54060,\n",
       " 115449,\n",
       " 88802,\n",
       " 116221,\n",
       " 117874,\n",
       " 20106,\n",
       " 16242,\n",
       " 77124,\n",
       " 115596,\n",
       " 49751,\n",
       " 30297,\n",
       " 70824,\n",
       " 15330,\n",
       " 51592,\n",
       " 76842,\n",
       " 59095,\n",
       " 17046,\n",
       " 74259,\n",
       " 52150,\n",
       " 62973,\n",
       " 117431,\n",
       " 88140,\n",
       " 40287,\n",
       " 111718,\n",
       " 115206,\n",
       " 74915,\n",
       " 22947,\n",
       " 36182,\n",
       " 113100,\n",
       " 98504,\n",
       " 27415,\n",
       " 20282,\n",
       " 100923,\n",
       " 43288,\n",
       " 35979,\n",
       " 44423,\n",
       " 75340,\n",
       " 76307,\n",
       " 51272,\n",
       " 50582,\n",
       " 71221,\n",
       " 41352,\n",
       " 46448,\n",
       " 59204,\n",
       " 93507,\n",
       " 48154,\n",
       " 108756,\n",
       " 84594,\n",
       " 110411,\n",
       " 16584,\n",
       " 43931,\n",
       " 54083,\n",
       " 32313,\n",
       " 65806,\n",
       " 19632,\n",
       " 108039,\n",
       " 16007,\n",
       " 89101,\n",
       " 12859,\n",
       " 115961,\n",
       " 28980,\n",
       " 51545,\n",
       " 7425,\n",
       " 119044,\n",
       " 65553,\n",
       " 28469,\n",
       " 65628,\n",
       " 115684,\n",
       " 74375,\n",
       " 118443,\n",
       " 68756,\n",
       " 70707,\n",
       " 85423,\n",
       " 83959,\n",
       " 113010,\n",
       " 109781,\n",
       " 7595,\n",
       " 87414,\n",
       " 117133,\n",
       " 50528,\n",
       " 7041,\n",
       " 117655,\n",
       " 10896,\n",
       " 82292,\n",
       " 98863,\n",
       " 50929,\n",
       " 98647,\n",
       " 111299,\n",
       " 34284,\n",
       " 14329,\n",
       " 52962,\n",
       " 30907,\n",
       " 110298,\n",
       " 6428,\n",
       " 49039,\n",
       " 113932,\n",
       " 73158,\n",
       " 47471,\n",
       " 42014,\n",
       " 94444,\n",
       " 62663,\n",
       " 52082,\n",
       " 35763,\n",
       " 94506,\n",
       " 111191,\n",
       " 112742,\n",
       " 89882,\n",
       " 21526,\n",
       " 16902,\n",
       " 11513,\n",
       " 101041,\n",
       " 42828,\n",
       " 101906,\n",
       " 90372,\n",
       " 111605,\n",
       " 75188,\n",
       " 6199,\n",
       " 29471,\n",
       " 112117,\n",
       " 104456,\n",
       " 13719,\n",
       " 39387,\n",
       " 44859,\n",
       " 117799,\n",
       " 18152,\n",
       " 17235,\n",
       " 7572,\n",
       " 29730,\n",
       " 110338,\n",
       " 99411,\n",
       " 81138,\n",
       " 37101,\n",
       " 5584,\n",
       " 21725,\n",
       " 47829,\n",
       " 72851,\n",
       " 84405,\n",
       " 35741,\n",
       " 22917,\n",
       " 46467,\n",
       " 35021,\n",
       " 73598,\n",
       " 51096,\n",
       " 13946,\n",
       " 4039,\n",
       " 52492,\n",
       " 69986,\n",
       " 43788,\n",
       " 88397,\n",
       " 23582,\n",
       " 105719,\n",
       " 97990,\n",
       " 22399,\n",
       " 81568,\n",
       " 20347,\n",
       " 67915,\n",
       " 40465,\n",
       " 79962,\n",
       " 14556,\n",
       " 106714,\n",
       " 4493,\n",
       " 27438,\n",
       " 4599,\n",
       " 114706,\n",
       " 54642,\n",
       " 120180,\n",
       " 88271,\n",
       " 48892,\n",
       " 19878,\n",
       " 112181,\n",
       " 29115,\n",
       " 40614,\n",
       " 76363,\n",
       " 119251,\n",
       " 115912,\n",
       " 82036,\n",
       " 14023,\n",
       " 117723,\n",
       " 81888,\n",
       " 37166,\n",
       " 78079,\n",
       " 25629,\n",
       " 82373,\n",
       " 84945,\n",
       " 68026,\n",
       " 57231,\n",
       " 16939,\n",
       " 92122,\n",
       " 25657,\n",
       " 22582,\n",
       " 62729,\n",
       " 103591,\n",
       " 56573,\n",
       " 84740,\n",
       " 107140,\n",
       " 106026,\n",
       " 70253,\n",
       " 76416,\n",
       " 71093,\n",
       " 37014,\n",
       " 63605,\n",
       " 71748,\n",
       " 1280,\n",
       " 62739,\n",
       " 114348,\n",
       " 61399,\n",
       " 89267,\n",
       " 80272,\n",
       " 46708,\n",
       " 31871,\n",
       " 38509,\n",
       " 9767,\n",
       " 26463,\n",
       " 21856,\n",
       " 108709,\n",
       " 24752,\n",
       " 4432,\n",
       " 62602,\n",
       " 43531,\n",
       " 68389,\n",
       " 7526,\n",
       " 56502,\n",
       " 72475,\n",
       " 67327,\n",
       " 93696,\n",
       " 100767,\n",
       " 15940,\n",
       " 38388,\n",
       " 53392,\n",
       " 96355,\n",
       " 97998,\n",
       " 81781,\n",
       " 57329,\n",
       " 61502,\n",
       " 71540,\n",
       " 7376,\n",
       " 15264,\n",
       " 94286,\n",
       " 47504,\n",
       " 4546,\n",
       " 39713,\n",
       " 1459,\n",
       " 113291,\n",
       " 52390,\n",
       " 15948,\n",
       " 89004,\n",
       " 17457,\n",
       " 86035,\n",
       " 22423,\n",
       " 115522,\n",
       " 63182,\n",
       " 55660,\n",
       " 72303,\n",
       " 55625,\n",
       " 28747,\n",
       " 6462,\n",
       " 70693,\n",
       " 41133,\n",
       " 85846,\n",
       " 111934,\n",
       " 1285,\n",
       " 95706,\n",
       " 32143,\n",
       " 82123,\n",
       " 97354,\n",
       " 3156,\n",
       " 105662,\n",
       " 56658,\n",
       " 110420,\n",
       " 86642,\n",
       " 96730,\n",
       " 4196,\n",
       " 14327,\n",
       " 29337,\n",
       " 69774,\n",
       " 12818,\n",
       " 102561,\n",
       " 99883,\n",
       " 94616,\n",
       " 6467,\n",
       " 38870,\n",
       " 23513,\n",
       " 79268,\n",
       " 66265,\n",
       " 83218,\n",
       " 35317,\n",
       " 16927,\n",
       " 37045,\n",
       " 115064,\n",
       " 32455,\n",
       " 14665,\n",
       " 1367,\n",
       " 89595,\n",
       " 16860,\n",
       " 43142,\n",
       " 6215,\n",
       " 114876,\n",
       " 32849,\n",
       " 29920,\n",
       " 10259,\n",
       " 54594,\n",
       " 91659,\n",
       " 22142,\n",
       " 109854,\n",
       " 66713,\n",
       " 52172,\n",
       " 114512,\n",
       " 98393,\n",
       " 70792,\n",
       " 1576,\n",
       " 23983,\n",
       " 31509,\n",
       " 118360,\n",
       " 39759,\n",
       " 74059,\n",
       " 84863,\n",
       " 11714,\n",
       " 65453,\n",
       " 15753,\n",
       " 58288,\n",
       " 65249,\n",
       " 9165,\n",
       " 9253,\n",
       " 40485,\n",
       " 96025,\n",
       " 64747,\n",
       " 100289,\n",
       " 112667,\n",
       " 41740,\n",
       " 38287,\n",
       " 74369,\n",
       " 1759,\n",
       " 5939,\n",
       " 80239,\n",
       " 78934,\n",
       " 33816,\n",
       " 97294,\n",
       " 41990,\n",
       " 47741,\n",
       " 7474,\n",
       " 114552,\n",
       " 28606,\n",
       " 97263,\n",
       " 48705,\n",
       " 57949,\n",
       " 64640,\n",
       " 108863,\n",
       " 59651,\n",
       " 38641,\n",
       " 75151,\n",
       " 7434,\n",
       " 42386,\n",
       " 66471,\n",
       " 105961,\n",
       " 106382,\n",
       " 5626,\n",
       " 10798,\n",
       " 40032,\n",
       " 47900,\n",
       " 38993,\n",
       " 18584,\n",
       " 73921,\n",
       " 6268,\n",
       " 116585,\n",
       " 83277,\n",
       " 29708,\n",
       " 4284,\n",
       " 9455,\n",
       " 119922,\n",
       " 18078,\n",
       " 16254,\n",
       " 109532,\n",
       " 116898,\n",
       " 55097,\n",
       " 119100,\n",
       " 105119,\n",
       " 36239,\n",
       " 40180,\n",
       " 97988,\n",
       " 66004,\n",
       " 74104,\n",
       " 89328,\n",
       " 99510,\n",
       " 66923,\n",
       " 34971,\n",
       " 68582,\n",
       " 71585,\n",
       " 93155,\n",
       " 12124,\n",
       " 43076,\n",
       " 45356,\n",
       " 67661,\n",
       " 95490,\n",
       " 108342,\n",
       " 51392,\n",
       " 17978,\n",
       " 44027,\n",
       " 112190,\n",
       " 83438,\n",
       " 44273,\n",
       " 20149,\n",
       " 52976,\n",
       " 38435,\n",
       " 9683,\n",
       " 31385,\n",
       " 88680,\n",
       " 96185,\n",
       " 24124,\n",
       " 84813,\n",
       " 111410,\n",
       " 2424,\n",
       " 27734,\n",
       " 79625,\n",
       " 80637,\n",
       " 99314,\n",
       " 16221,\n",
       " 10862,\n",
       " 50632,\n",
       " 80679,\n",
       " 41260,\n",
       " 61727,\n",
       " 85533,\n",
       " 10276,\n",
       " 41486,\n",
       " 32977,\n",
       " 20845,\n",
       " 43968,\n",
       " 42807,\n",
       " 4288,\n",
       " 93896,\n",
       " 57894,\n",
       " 751,\n",
       " 27340,\n",
       " 91843,\n",
       " 11508,\n",
       " 97790,\n",
       " 15072,\n",
       " 117437,\n",
       " 65976,\n",
       " 18311,\n",
       " 17982,\n",
       " 112857,\n",
       " 89688,\n",
       " 63493,\n",
       " 97213,\n",
       " 66282,\n",
       " 4304,\n",
       " 29442,\n",
       " 112007,\n",
       " 96822,\n",
       " 62246,\n",
       " 7891,\n",
       " 38850,\n",
       " 52144,\n",
       " 50123,\n",
       " 64975,\n",
       " 78521,\n",
       " 93153,\n",
       " 115843,\n",
       " 50977,\n",
       " 56976,\n",
       " 17491,\n",
       " 7542,\n",
       " 44869,\n",
       " 44310,\n",
       " 59455,\n",
       " 108031,\n",
       " 108880,\n",
       " 15480,\n",
       " 19679,\n",
       " 92163,\n",
       " 110927,\n",
       " 40844,\n",
       " 20414,\n",
       " 112457,\n",
       " 49664,\n",
       " 103463,\n",
       " 45842,\n",
       " 67672,\n",
       " 47042,\n",
       " 26863,\n",
       " 12216,\n",
       " 11242,\n",
       " 51068,\n",
       " 68826,\n",
       " 8479,\n",
       " 11397,\n",
       " 6686,\n",
       " 48902,\n",
       " 12354,\n",
       " 107163,\n",
       " 113479,\n",
       " 88843,\n",
       " 81853,\n",
       " 101490,\n",
       " 28199,\n",
       " 65701,\n",
       " 82334,\n",
       " 80192,\n",
       " 43851,\n",
       " 37880,\n",
       " 42291,\n",
       " 49487,\n",
       " 109928,\n",
       " 111449,\n",
       " 45152,\n",
       " 21997,\n",
       " 7946,\n",
       " 45209,\n",
       " 92316,\n",
       " 81938,\n",
       " 57226,\n",
       " 78655,\n",
       " 101840,\n",
       " 90860,\n",
       " 113383,\n",
       " 91356,\n",
       " 21811,\n",
       " 106961,\n",
       " 98162,\n",
       " 105950,\n",
       " 88571,\n",
       " 6519,\n",
       " 88004,\n",
       " 1305,\n",
       " 55938,\n",
       " 94792,\n",
       " 59417,\n",
       " 59831,\n",
       " 66856,\n",
       " 72482,\n",
       " 42760,\n",
       " 96853,\n",
       " 27063,\n",
       " 85101,\n",
       " 79721,\n",
       " 60482,\n",
       " 116658,\n",
       " 35847,\n",
       " ...]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target_loader.dataset.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "36c01977",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Subset(target_dataset_torch, test_target_loader.dataset.indices).dataset.tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8e8324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_dataset[0].long(), test_dataset[1].long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "698ccbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(test_dataset[3].numpy(), preds.detach().numpy() >= 0.5)\n",
    "conf = precision_recall_fscore_support(test_dataset[3].numpy(), preds.detach().numpy() >= 0.5, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "74694575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9737570773236351\n",
      "prec: 0.9754540686148129\n",
      "recall: 0.9962410111135324\n",
      "f1: 0.9857379648637358\n"
     ]
    }
   ],
   "source": [
    "print(\"acc:\", acc)\n",
    "print(\"prec:\", conf[0])\n",
    "print(\"recall:\", conf[1])\n",
    "print(\"f1:\", conf[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6136e1b6",
   "metadata": {},
   "source": [
    "# NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eaacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "# Neural collaborative filtering (NCF) for cross-domain recommendation\n",
    "# Uses precomputed item feature vectors for source / target domains.\n",
    "# Expects these variables to exist in the notebook:\n",
    "#   - user_dict (dict): maps user_id -> user_idx (0-based)\n",
    "#   - n_users (int)\n",
    "#   - source_item_feature_vectors (np.array or torch.Tensor)  # shape (n_source_items, feat_dim)\n",
    "#   - target_item_feature_vectors (np.array or torch.Tensor)  # shape (n_target_items, feat_dim)\n",
    "#   - source_loader, target_loader (torch.utils.data.DataLoader) or source_dataset_torch/target_dataset_torch\n",
    "# If prebuilt loaders are not available, you can create them from source_dataset_torch / target_dataset_torch.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Collaborative Filtering that concatenates a learned user embedding with provided\n",
    "    item feature vectors (from source/target) and passes them through an MLP to predict rating.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        source_item_features,  # numpy array or torch.Tensor (n_source_items, feat_dim)\n",
    "        target_item_features,  # numpy array or torch.Tensor (n_target_items, feat_dim)\n",
    "        user_emb_dim: int = 64,\n",
    "        mlp_layers: list = (128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        freeze_item_features: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # user embedding\n",
    "        self.user_emb = nn.Embedding(n_users, user_emb_dim)\n",
    "\n",
    "        # item features: convert to tensors and make Embedding-like lookup via from_pretrained\n",
    "        src_feat = torch.as_tensor(source_item_features, dtype=torch.float32)\n",
    "        tgt_feat = torch.as_tensor(target_item_features, dtype=torch.float32)\n",
    "        self.src_feat_dim = src_feat.shape[1]\n",
    "        self.tgt_feat_dim = tgt_feat.shape[1]\n",
    "\n",
    "        self.item_feat_src = nn.Embedding.from_pretrained(src_feat, freeze=freeze_item_features)\n",
    "        self.item_feat_tgt = nn.Embedding.from_pretrained(tgt_feat, freeze=freeze_item_features)\n",
    "\n",
    "        # MLP that takes concat(user_emb, item_feat) -> rating scalar\n",
    "        input_dim_src = user_emb_dim + self.src_feat_dim\n",
    "        input_dim_tgt = user_emb_dim + self.tgt_feat_dim\n",
    "        # For simplicity use same MLP architecture but different first layer shapes handled at forward\n",
    "\n",
    "        # Build MLP for source domain and target domain separately if feature dims differ\n",
    "        def build_mlp(input_dim):\n",
    "            layers = []\n",
    "            prev_dim = input_dim\n",
    "\n",
    "            for hidden_dim in mlp_layers:\n",
    "                layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                prev_dim = hidden_dim\n",
    "\n",
    "            layers.append(nn.Linear(prev_dim, 1))  # final scalar\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.mlp_src = build_mlp(input_dim_src)\n",
    "        # reuse architecture for target but with target input dim\n",
    "        self.mlp_tgt = build_mlp(input_dim_tgt)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "\n",
    "        # pretrained item features already set; MLP init\n",
    "        for m in self.mlp_src:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "        for m in self.mlp_tgt:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor, domain: str):\n",
    "        \"\"\"\n",
    "        users: (batch,)\n",
    "        items: (batch,) -- item indices local to domain (0..n_items_domain-1)\n",
    "        domain: \"source\" or \"target\"\n",
    "        returns: (batch,) predicted scalar ratings\n",
    "        \"\"\"\n",
    "        u = self.user_emb(users)  # (batch, user_emb_dim)\n",
    "\n",
    "        if domain == \"source\":\n",
    "            i_feat = self.item_feat_src(items)  # (batch, feat_dim)\n",
    "            x = torch.cat([u, i_feat], dim=-1)\n",
    "            out = self.mlp_src(x).squeeze(-1)\n",
    "\n",
    "        elif domain == \"target\":\n",
    "            i_feat = self.item_feat_tgt(items)\n",
    "            x = torch.cat([u, i_feat], dim=-1)\n",
    "            out = self.mlp_tgt(x).squeeze(-1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"domain must be 'source' or 'target'\")\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Training / evaluation helpers\n",
    "def train_ncf(\n",
    "    model: nn.Module,\n",
    "    source_loader,\n",
    "    target_loader,\n",
    "    epochs: int = 10,\n",
    "    lr: float = 1e-3,\n",
    "    weight_decay: float = 0.0,\n",
    "    device: torch.device = None,\n",
    "    report_every: int = 1,\n",
    "):\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for ep in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        for users, items, ratings in source_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"source\")\n",
    "            loss = loss_fn(preds, ratings)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        for users, items, ratings in target_loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "\n",
    "            preds = model(users, items, domain=\"target\")\n",
    "            loss = loss_fn(preds, ratings)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "\n",
    "        if ep % report_every == 0:\n",
    "            print(f\"Epoch {ep}/{epochs} avg MSE: {total_loss / max(1, n_batches):.6f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_ncf(model: nn.Module, loader, domain: str, device: torch.device = None):\n",
    "    device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    se = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in loader:\n",
    "            users = users.long().to(device)\n",
    "            items = items.long().to(device)\n",
    "            ratings = ratings.float().to(device)\n",
    "            preds = model(users, items, domain=domain)\n",
    "            se += ((preds - ratings) ** 2).sum().item()\n",
    "            n += ratings.numel()\n",
    "    rmse = math.sqrt(se / n) if n > 0 else float(\"nan\")\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c66744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "class NCF(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural Collaborative Filtering that concatenates a learned user embedding with provided\n",
    "    item feature vectors (from source/target) and passes them through an MLP to predict rating.\n",
    "\n",
    "    This version shares a base user embedding across domains and applies small domain-specific\n",
    "    adapters (learned transforms) so the model can learn domain-specific user behavior while\n",
    "    still sharing signal across domains (helpful for overlapping users).\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_users: int,\n",
    "        source_item_features,  # numpy array or torch.Tensor (n_source_items, feat_dim)\n",
    "        target_item_features,  # numpy array or torch.Tensor (n_target_items, feat_dim)\n",
    "        user_emb_dim: int = 64,\n",
    "        mlp_layers: list = (128, 64, 32),\n",
    "        dropout: float = 0.2,\n",
    "        freeze_item_features: bool = True,\n",
    "        adapter_hidden: int = None,  # if set, use a small hidden layer in adapters\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # shared base user embedding (size = total unique users across both domains)\n",
    "        self.user_emb = nn.Embedding(n_users, user_emb_dim)\n",
    "\n",
    "        # lightweight domain adapters: map base user embedding -> domain-specific user embedding\n",
    "        if adapter_hidden is None:\n",
    "            # single linear adapter\n",
    "            self.user_adapter_src = nn.Linear(user_emb_dim, user_emb_dim)\n",
    "            self.user_adapter_tgt = nn.Linear(user_emb_dim, user_emb_dim)\n",
    "        else:\n",
    "            self.user_adapter_src = nn.Sequential(\n",
    "                nn.Linear(user_emb_dim, adapter_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(adapter_hidden, user_emb_dim),\n",
    "            )\n",
    "            self.user_adapter_tgt = nn.Sequential(\n",
    "                nn.Linear(user_emb_dim, adapter_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(adapter_hidden, user_emb_dim),\n",
    "            )\n",
    "\n",
    "        # item features: convert to tensors and make Embedding-like lookup via from_pretrained\n",
    "        src_feat = torch.as_tensor(source_item_features, dtype=torch.float32)\n",
    "        tgt_feat = torch.as_tensor(target_item_features, dtype=torch.float32)\n",
    "        self.src_feat_dim = src_feat.shape[1]\n",
    "        self.tgt_feat_dim = tgt_feat.shape[1]\n",
    "\n",
    "        self.item_feat_src = nn.Embedding.from_pretrained(src_feat, freeze=freeze_item_features)\n",
    "        self.item_feat_tgt = nn.Embedding.from_pretrained(tgt_feat, freeze=freeze_item_features)\n",
    "\n",
    "        # MLPs for each domain\n",
    "        input_dim_src = user_emb_dim + self.src_feat_dim\n",
    "        input_dim_tgt = user_emb_dim + self.tgt_feat_dim\n",
    "\n",
    "        def build_mlp(input_dim):\n",
    "            layers = []\n",
    "            prev = input_dim\n",
    "            for h in mlp_layers:\n",
    "                layers.append(nn.Linear(prev, h))\n",
    "                layers.append(nn.ReLU())\n",
    "                layers.append(nn.Dropout(p=dropout))\n",
    "                prev = h\n",
    "            layers.append(nn.Linear(prev, 1))\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        self.mlp_src = build_mlp(input_dim_src)\n",
    "        self.mlp_tgt = build_mlp(input_dim_tgt)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        nn.init.normal_(self.user_emb.weight, 0, 0.1)\n",
    "        # adapter init\n",
    "        def init_adapter(m):\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        self.user_adapter_src.apply(init_adapter)\n",
    "        self.user_adapter_tgt.apply(init_adapter)\n",
    "        # MLP init\n",
    "        for m in self.mlp_src:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "        for m in self.mlp_tgt:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, users: torch.LongTensor, items: torch.LongTensor, domain: str):\n",
    "        \"\"\"\n",
    "        users: (batch,)\n",
    "        items: (batch,) -- item indices local to domain (0..n_items_domain-1)\n",
    "        domain: \"source\" or \"target\"\n",
    "        returns: (batch,) predicted scalar ratings\n",
    "        \"\"\"\n",
    "        u = self.user_emb(users)  # (batch, user_emb_dim)\n",
    "        # domain-specific adapter: lets the model learn per-domain user behavior while sharing base info\n",
    "        if domain == \"source\":\n",
    "            u_dom = self.user_adapter_src(u)\n",
    "            i_feat = self.item_feat_src(items)\n",
    "            x = torch.cat([u_dom, i_feat], dim=-1)\n",
    "            out = self.mlp_src(x).squeeze(-1)\n",
    "        elif domain == \"target\":\n",
    "            u_dom = self.user_adapter_tgt(u)\n",
    "            i_feat = self.item_feat_tgt(items)\n",
    "            x = torch.cat([u_dom, i_feat], dim=-1)\n",
    "            out = self.mlp_tgt(x).squeeze(-1)\n",
    "        else:\n",
    "            raise ValueError(\"domain must be 'source' or 'target'\")\n",
    "        return out\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181772f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (assumes the named variables exist in the notebook):\n",
    "# - source_item_feature_vectors, target_item_feature_vectors: arrays/tensors of item features\n",
    "# - source_loader, target_loader: DataLoader objects producing (user_idx, item_idx, rating)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8613ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 avg MSE: 3.040604\n",
      "Epoch 2/50 avg MSE: 1.408292\n",
      "Epoch 3/50 avg MSE: 1.271468\n",
      "Epoch 4/50 avg MSE: 1.212633\n",
      "Epoch 5/50 avg MSE: 1.175297\n",
      "Epoch 6/50 avg MSE: 1.136314\n",
      "Epoch 7/50 avg MSE: 1.113781\n",
      "Epoch 8/50 avg MSE: 1.085496\n",
      "Epoch 9/50 avg MSE: 1.059976\n",
      "Epoch 10/50 avg MSE: 1.043349\n",
      "Epoch 11/50 avg MSE: 1.024997\n",
      "Epoch 12/50 avg MSE: 1.004933\n",
      "Epoch 13/50 avg MSE: 0.988168\n",
      "Epoch 14/50 avg MSE: 0.970328\n",
      "Epoch 15/50 avg MSE: 0.953801\n",
      "Epoch 16/50 avg MSE: 0.931623\n",
      "Epoch 17/50 avg MSE: 0.916105\n",
      "Epoch 18/50 avg MSE: 0.898908\n",
      "Epoch 19/50 avg MSE: 0.881925\n",
      "Epoch 20/50 avg MSE: 0.862051\n",
      "Epoch 21/50 avg MSE: 0.847788\n",
      "Epoch 22/50 avg MSE: 0.831449\n",
      "Epoch 23/50 avg MSE: 0.812696\n",
      "Epoch 24/50 avg MSE: 0.797843\n",
      "Epoch 25/50 avg MSE: 0.781795\n",
      "Epoch 26/50 avg MSE: 0.762961\n",
      "Epoch 27/50 avg MSE: 0.748274\n",
      "Epoch 28/50 avg MSE: 0.734222\n",
      "Epoch 29/50 avg MSE: 0.716033\n",
      "Epoch 30/50 avg MSE: 0.698651\n",
      "Epoch 31/50 avg MSE: 0.688903\n",
      "Epoch 32/50 avg MSE: 0.675081\n",
      "Epoch 33/50 avg MSE: 0.662427\n",
      "Epoch 34/50 avg MSE: 0.653715\n",
      "Epoch 35/50 avg MSE: 0.643205\n",
      "Epoch 36/50 avg MSE: 0.634367\n",
      "Epoch 37/50 avg MSE: 0.619963\n",
      "Epoch 38/50 avg MSE: 0.611793\n",
      "Epoch 39/50 avg MSE: 0.602002\n",
      "Epoch 40/50 avg MSE: 0.591835\n",
      "Epoch 41/50 avg MSE: 0.584090\n",
      "Epoch 42/50 avg MSE: 0.578574\n",
      "Epoch 43/50 avg MSE: 0.568345\n",
      "Epoch 44/50 avg MSE: 0.558311\n",
      "Epoch 45/50 avg MSE: 0.551414\n",
      "Epoch 46/50 avg MSE: 0.545100\n",
      "Epoch 47/50 avg MSE: 0.539167\n",
      "Epoch 48/50 avg MSE: 0.530731\n",
      "Epoch 49/50 avg MSE: 0.522152\n",
      "Epoch 50/50 avg MSE: 0.517012\n",
      "Target RMSE: 0.627872705477407\n"
     ]
    }
   ],
   "source": [
    "model = NCF(n_users=n_users,\n",
    "                 source_item_features=source_item_feature_vectors,\n",
    "                 target_item_features=target_item_feature_vectors,\n",
    "                 user_emb_dim=64,\n",
    "                 mlp_layers=(128,64,32),\n",
    "                 dropout=0.2,\n",
    "                 freeze_item_features=True)\n",
    "\n",
    "train_ncf(model, source_loader, target_loader, epochs=50, lr=1e-3)\n",
    "print(\"Target RMSE:\", evaluate_ncf(model, target_loader, domain=\"target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94c63c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.forward(tensor_target_users.long(), tensor_target_items.long(), 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40b6b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_preds = [int(e >= 3) for e in preds]\n",
    "bin_ratings = [int(e >= 3) for e in tensor_target_ratings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b674bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "acc = accuracy_score(bin_ratings, bin_preds)\n",
    "conf = precision_recall_fscore_support(bin_ratings, bin_preds, average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b45e3c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9506054469562343\n",
      "prec: 0.9757467799397095\n",
      "recall: 0.969846371758553\n",
      "f1: 0.9727876287533127\n"
     ]
    }
   ],
   "source": [
    "print(\"acc:\", acc)\n",
    "print(\"prec:\", conf[0])\n",
    "print(\"recall:\", conf[1])\n",
    "print(\"f1:\", conf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39263689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
